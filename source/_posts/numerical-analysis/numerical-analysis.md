---
title: 矩阵特征值计算
date: 2025-05-27 00:44:35
tags:
    - mathematics
    - numerical-analysis
excerpt: 本文介绍了矩阵特征值的计算方法，包括Gerschgorin圆盘定理和幂法，重点讨论了特征值分布的几何定位及其在数值分析中的应用。
---
## 特征值分布与圆盘定理的应用

在数值分析与线性代数中，特征值的分布对理解矩阵性质至关重要。例如，迭代法 $ x^{(k+1)} = Bx^{(k)} + f $ 的收敛性取决于矩阵 $ B $ 的谱半径 $ \rho(B) $，即其特征值的最大模值。此外，矩阵的2-条件数 $ \text{cond}(A)_2 $ 也与特征值的极值相关。因此，如何快速估计特征值的范围成为关键问题。

### 圆盘定理：特征值的几何定位  
Gerschgorin圆盘定理为此提供了直观的工具。对于矩阵 $ A \in \mathbb{C}^{n \times n} $，其第 $ k $ 个圆盘定义为：以对角线元素 $ a_{kk} $ 为圆心，半径 $ r_k = \sum_{j \neq k} |a_{kj}| $（即该行非对角元绝对值之和）。定理指出：  
1. 所有特征值必落在这些圆盘的并集中。  
2. 若存在 $ m $ 个连通且与其他分离的圆盘，则其中恰好包含 $ m $ 个特征值。  

证明思路基于特征方程 $ (\lambda - a_{kk})x_k = \sum_{j \neq k} a_{kj}x_j $，通过最大分量 $ x_k $ 的模长分析，导出 $ |\lambda - a_{kk}| \leq r_k $，从而确定特征值的分布范围。

### 应用实例与推论  
定理 5.11：若实矩阵 $ A $ 的对角元均为正，且满足：  
1. 严格对角占优（即每行对角元绝对值大于该行非对角元绝对值之和），则所有特征值的实部 $ \text{Re}(\lambda) > 0 $。  
2. 若 $ A $ 还是对称的且对角占优，则可进一步推断其半正定性（具体结论可参考教材拓展）。  

例5.3：估计矩阵  
$$
A = \begin{bmatrix}
4 & 1 & 0 \\
1 & 0 & -1 \\
1 & 1 & -4
\end{bmatrix}
$$  
的特征值分布。  
1. 直接应用圆盘定理：  
   - 第一个圆盘 $ D_1 $ 以4为中心，半径1（范围 $[3,5]$），与另外两个圆盘分离，必含一个实特征值。  
   - 第二、三个圆盘分别为 $[-1,1]$ 和 $[-5,-3]$。  
2. 对 $ A^T $ 应用圆盘定理：  
   - 转置后，第三个圆盘 $ D_3' $ 以-4为中心，半径2（范围 $[-6,-2]$），分离后修正为 $[-5,-3]$，必含另一实特征值。  

综合结果：  
$$
\lambda_1 \in [3,5], \quad \lambda_3 \in [-5,-3], \quad \lambda_2 \in [-2,2]
$$  
实际计算得特征值为4.2030、-3.7601、-0.4429，均在估计范围内。此例还表明，通过相似变换（如课本例5.4）可进一步优化估计精度。


## 幂法：计算矩阵主特征值的实用方法

幂法是数值线性代数中用于计算矩阵主特征值（模最大的特征值）及其对应特征向量的经典迭代算法。其核心思想是通过不断用矩阵作用于一初始向量，使向量逐渐对齐主特征向量的方向。以下从理论、实现到应用细节展开说明。


### 幂法的收敛性
定理5.12：若矩阵 $ A $ 存在唯一的主特征值 $ \lambda_1 $（满足 $ |\lambda_1| > |\lambda_j| $ 对所有 $ j \neq 1 $），且初始向量 $ v_0 $ 在 $ \lambda_1 $ 对应的特征向量方向上的分量不为零，则迭代过程  
$$
v_k = Av_{k-1} \quad (k=1,2,\dots)
$$ 
生成的序列 $ v_k $ 会收敛到 $ \lambda_1 $ 对应的特征向量。

证明要点：  
假设 $ A $ 是非亏损矩阵（即具有完备的特征向量基），设其线性无关特征向量为 $ \hat{x}_1, \dots, \hat{x}_n $，初始向量可分解为：  
$$
v_0 = \alpha_1 \hat{x}_1 + \cdots + \alpha_n \hat{x}_n \quad (\alpha_1 \neq 0).
$$ 
迭代后得：  
$$
v_k = A^k v_0 = \alpha_1 \lambda_1^k \hat{x}_1 + \alpha_2 \lambda_2^k \hat{x}_2 + \cdots + \alpha_n \lambda_n^k \hat{x}_n.
$$ 
由于 $ |\lambda_1| > |\lambda_j| $，当 $ k \to \infty $ 时，高阶项 $ \left(\frac{\lambda_j}{\lambda_1}\right)^k $ 趋近于零，因此 $ v_k $ 的方向趋近于 $ \hat{x}_1 $。进一步，若记录 $ v_k $ 中绝对值最大的分量下标 $ j $，则：  
$$
\lim_{k \to \infty} \frac{(v_{k+1})_j}{(v_k)_j} = \lambda_1.
$


### 改进：向量规格化
幂法的直接迭代可能导致向量分量迅速增长或缩小（上溢/下溢）。规格化是解决此问题的关键技巧。

规格化方法：  
每步迭代后，将向量除以其绝对值最大的分量（或范数），确保其最大分量为1。例如：  
- 向量 $ v = [3, -5, 0]^T $，规格化后为 $ u = \left[ -\frac{3}{5}, 1, 0 \right]^T $。  
- 无穷范数规格化：$ \|u\|_\infty = 1 $，且 $ \max(u) = 1 $。

定理5.13：  
若迭代过程中每步进行规格化：  
$$
u_k = \frac{v_k}{\max(v_k)}, \quad v_k = Au_{k-1},
$$ 
则：  
1. 规格化后的向量序列 $ u_k $ 收敛到主特征向量的规格化形式：  
   $$
   \lim_{k \to \infty} u_k = \frac{\hat{x}_1}{\max(\hat{x}_1)}.
   $$ 
2. 迭代中记录的 $ \max(v_k) $ 收敛到主特征值 $ \lambda_1 $。

### 加速幂法的收敛  
1. 原点位移技术  
通过平移矩阵特征值加速收敛：令 $ B = A - sI $，其特征值为 $ \lambda_i - s $。选择适当的位移 $ s $，使得次主特征值与主特征值的模长比缩小（即 $ \left|\frac{\lambda_2 - s}{\lambda_1 - s}\right| < \left|\frac{\lambda_2}{\lambda_1}\right| $），从而提升幂法收敛速度。  

2. 瑞利商加速（实对称阵）  
对实对称矩阵 $ A $，利用瑞利商 $ R(x) = \frac{x^T Ax}{x^T x} $ 估计特征值：  
- Th5.15：瑞利商满足 $ \lambda_{\min} \leq R(x) \leq \lambda_{\max} $，当 $ x $ 为特征向量时取等。  
- Th5.16：结合幂法，每步计算 $ R(u_k) $，其收敛速度提升至 $ O((\lambda_2/\lambda_1)^{2k}) $，优于传统幂法的 $ O((\lambda_2/\lambda_1)^k) $。


### 算法实现
算法5.1（计算主特征值及特征向量）：  
输入：矩阵 $ A $，初始随机向量 $ u_0 $，判停阈值 $ \epsilon $。  
输出：主特征值 $ \lambda_1 $，规格化的主特征向量 $ x_1 $。  

1. 初始化：选择随机非零向量 $ u_0 $。  
2. 迭代循环：  
   - 计算 $ v = Au_{k-1} $。  
   - 近似主特征值：$ \lambda_1^{(k)} = \max(v) $ （或使用加速方法，计算瑞利商）。  
   - 规格化向量：$ u_k = v / \lambda_1^{(k)} $。  
   - 检查判停条件（如 $ |\lambda_1^{(k)} - \lambda_1^{(k-1)}| < \epsilon $）。  
3. 终止：输出 $ \lambda_1 = \lambda_1^{(k)} $，$ x_1 = u_k $。  

关键细节：  
- 稀疏矩阵友好：每步仅需一次矩阵-向量乘法，适合大规模稀疏矩阵。  
- 数值稳定性：规格化避免数值溢出，同时加速收敛。  
- 前提条件：主特征值唯一且非零，初始向量在主特征方向的分量不为零。  


### 应用注意事项
1. 判停准则：常用相邻迭代步的 $ \lambda_1 $ 差值小于阈值，或设定最大迭代次数。  
2. 特征值符号：若主特征值为负，$ \max(v_k) $ 的符号会震荡，需取绝对值判断收敛。  
3. 多重主特征值：若存在多个模相等的最大特征值（如 $ \lambda_1 = -\lambda_2 $），幂法可能失效。  

